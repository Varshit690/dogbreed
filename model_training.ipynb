{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcdad6bc",
   "metadata": {},
   "source": [
    "# Dog Breed Identification - Model Training\n",
    "\n",
    "This notebook contains the code for training a deep learning model to identify dog breeds from images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2d4fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0bf1aae",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "776784cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537a8ae0",
   "metadata": {},
   "source": [
    "## Data Augmentation and Dataset Loading\n",
    "\n",
    "**IMPORTANT:** Populate the dataset folders with dog breed images before running this section:\n",
    "- Place training images in `dataset/train/[breed_name]/` \n",
    "- Place test images in `dataset/test/[breed_name]/`\n",
    "- Supported formats: .jpg, .png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f138d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a627b6d5",
   "metadata": {},
   "source": [
    "## Verify Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "958249c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images found: 12\n",
      "Test images found: 12\n",
      "\n",
      "✅ Dataset looks ready for training!\n",
      "Found 12 training images and 12 test images.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Check dataset structure\n",
    "train_dir = \"dataset/train\"\n",
    "test_dir = \"dataset/test\"\n",
    "\n",
    "# Count total images\n",
    "# Support common image extensions (case variations included)\n",
    "extensions = ['jpg','jpeg','png','JPG','JPEG','PNG']\n",
    "train_images = []\n",
    "test_images = []\n",
    "for ext in extensions:\n",
    "    train_images += glob.glob(os.path.join(train_dir, f'*/*.{ext}'))\n",
    "    test_images += glob.glob(os.path.join(test_dir, f'*/*.{ext}'))\n",
    "\n",
    "print(f\"Training images found: {len(train_images)}\")\n",
    "print(f\"Test images found: {len(test_images)}\")\n",
    "\n",
    "if len(train_images) == 0 or len(test_images) == 0:\n",
    "    print(\"\\n⚠️  WARNING: Dataset appears empty or no supported image files were found.\")\n",
    "    print(\"Please add image files to the dataset folders, e.g.\")\n",
    "    print(\"  - dataset/train/[breed_name]/*.jpg (or .jpeg/.png)\")\n",
    "    print(\"  - dataset/test/[breed_name]/*.jpg (or .jpeg/.png)\")\n",
    "    print(\"Also check file name case (JPG vs jpg) and that subfolders exist for each class.\")\n",
    "else:\n",
    "    print(\"\\n✅ Dataset looks ready for training!\")\n",
    "    print(f\"Found {len(train_images)} training images and {len(test_images)} test images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "213a9c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy images for classes: ['pug', 'beagle']\n"
     ]
    }
   ],
   "source": [
    "# Create small dummy dataset (3 images per class) if you don't have real images yet\n",
    "try:\n",
    "    from PIL import Image\n",
    "except Exception:\n",
    "    import sys, subprocess\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'pillow'])\n",
    "    from PIL import Image\n",
    "import os\n",
    "train_dir = 'dataset/train'\n",
    "test_dir = 'dataset/test'\n",
    "classes = ['pug', 'beagle']  # change or extend as needed\n",
    "for base in (train_dir, test_dir):\n",
    "    for cls in classes:\n",
    "        d = os.path.join(base, cls)\n",
    "        os.makedirs(d, exist_ok=True)\n",
    "        for i in range(3):\n",
    "            img = Image.new('RGB', (128,128), (50 + i*50, 100 + i*30, 150 + i*20))\n",
    "            img.save(os.path.join(d, f'sample_{i}.png'))\n",
    "print('Created dummy images for classes:', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "523fb877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 images belonging to 2 classes.\n",
      "Found 6 images belonging to 3 classes.\n",
      "train_data.samples = 6\n",
      "test_data.samples = 6\n",
      "train_data.class_indices = {'beagle': 0, 'pug': 1}\n"
     ]
    }
   ],
   "source": [
    "train_data = train_datagen.flow_from_directory(\n",
    "    \"dataset/train\",\n",
    "    target_size=(128,128),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    ")\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    \"dataset/test\",\n",
    "    target_size=(128,128),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    ")\n",
    "\n",
    "# Print diagnostics so we can see why training might fail\n",
    "print(f\"train_data.samples = {train_data.samples}\")\n",
    "print(f\"test_data.samples = {test_data.samples}\")\n",
    "print(f\"train_data.class_indices = {train_data.class_indices}\")\n",
    "\n",
    "# Flag indicating whether data is present for training\n",
    "data_ready = (train_data.samples > 0 and test_data.samples > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42919802",
   "metadata": {},
   "source": [
    "## Build VGG19 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44abf1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG19(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    "    input_shape=(128,128,3)\n",
    ")\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "output = Dense(20, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc232384",
   "metadata": {},
   "source": [
    "## Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e04ba77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1d7583",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3a47aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 2), output.shape=(None, 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mdata_ready\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m() \u001b[38;5;129;01mand\u001b[39;00m data_ready:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_data\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDataset not ready for training. Add images to dataset/train and dataset/test, then re-run verification.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:1166\u001b[39m, in \u001b[36mcategorical_crossentropy\u001b[39m\u001b[34m(target, output, from_logits, axis)\u001b[39m\n\u001b[32m   1164\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target.shape, output.shape):\n\u001b[32m   1165\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 != e2:\n\u001b[32m-> \u001b[39m\u001b[32m1166\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1167\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mArguments `target` and `output` must have the same shape. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1168\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mReceived: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1169\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1170\u001b[39m         )\n\u001b[32m   1172\u001b[39m output, from_logits = _get_logits(\n\u001b[32m   1173\u001b[39m     output, from_logits, \u001b[33m\"\u001b[39m\u001b[33mSoftmax\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcategorical_crossentropy\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1174\u001b[39m )\n\u001b[32m   1175\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m from_logits:\n",
      "\u001b[31mValueError\u001b[39m: Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 2), output.shape=(None, 20)"
     ]
    }
   ],
   "source": [
    "if 'data_ready' in globals() and data_ready:\n",
    "    model.fit(\n",
    "        train_data,\n",
    "        epochs=6,\n",
    "        validation_data=test_data\n",
    "    )\n",
    "else:\n",
    "    print(\"Dataset not ready for training. Add images to dataset/train and dataset/test, then re-run verification.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92381095",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4529a3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"dogbreed.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
